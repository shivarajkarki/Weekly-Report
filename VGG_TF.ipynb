{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16:\n",
    "    \n",
    "    def __init__(self, img):\n",
    "        \n",
    "        #predefining functions and variables\n",
    "        self.convlayers()\n",
    "        self.fc_layers()\n",
    "        \n",
    "        #.. not needed\n",
    "        self.setup_kernel()\n",
    "        self.setup_conv()\n",
    "        self.setup_bias()\n",
    "        #.. **\n",
    "        \n",
    "        self.img = img\n",
    "        \n",
    "        \n",
    "    \n",
    "    #may not be useful..\n",
    "    #....,,, starting from here ,,,....\n",
    "    def setup_kernel(self, prev_ch, next_ch, K_name):\n",
    "        return tf.Variable(initializer=tf.truncated_normal(shape=[3, 3, prev_ch, next_ch], mean=0.0, stddev=1.0,\n",
    "                                                               seed = 1, name=K_name))\n",
    "    \n",
    "    def setup_conv(self, input_, kernel):\n",
    "        return tf.nn.conv2d(input_, kernel, strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    def setup_bias(self, next_ch, b_name):\n",
    "        return tf.get_variable(tf.zeros(next_ch), dtype=tf.float32, name = b_name)\n",
    "    #....,,, ending here ,,,....\n",
    "    \n",
    "    \n",
    "    #function for conv layer\n",
    "    def convlayers(self, curr_layer_str, input_ch, next_ch, conv_ip):\n",
    "        \n",
    "        #convlayer 1 kernel = (3,3), input channel = 3, output hannel = 64, \n",
    "        with tf.name_scope(curr_layer_str) as scope:\n",
    "            kernel = tf.Variable(initializer=tf.truncated_normal(shape=[3, 3, input_ch, next_ch], mean=0.0, \n",
    "                                                                 stddev=1.0, name= 'Weights'))\n",
    "            #kernel  = self.setup_kernel(input_ch, next_ch, 'Weights')\n",
    "            \n",
    "            conv = tf.nn.conv2d(conv_ip, kernel, strides=[1,1,1,1], padding='SAME')\n",
    "            #conv = self.setup_conv(conv_ip, kernel)\n",
    "            \n",
    "            bias = tf.get_variable(tf.zeros(next_ch), dtype=tf.float32, name = 'bias')\n",
    "            #bias = self.setup_bias(next_ch, 'bias')\n",
    "            \n",
    "            out = tf.nn.bias_add(conv, bias)\n",
    "            return tf.nn.relu(out, name = scope)\n",
    "    \n",
    "    #function for max pooling layer\n",
    "    def pooll(self, pool_ip, pool_name): #pool layer.. pooll\n",
    "        return tf.nn.max_pool(pool_ip, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID', name = pool_name)\n",
    "    \n",
    "    #function for fully connected layer\n",
    "    def fc_layers(fc_ip, ip_shape, op_shape, fc_name):\n",
    "        with tf.name_scope(fc_name) as scope:\n",
    "            fcw = tf.Variable(tf.truncated_normal([ip_shape, op_shape], mean = 0, stddev = 1.0, name='Weights'))\n",
    "            fcb = tf.Variable(tf.constant(1.0, shape = op_shape, name = 'bias'))\n",
    "            \n",
    "            fc = tf.nn.bias_add(tf.matmul(fc_ip, fcw), fcb)\n",
    "            \n",
    "            return tf.nn.relu(fc)\n",
    "    \n",
    "    \n",
    "    #VGG architecture\n",
    "    def VGG(self):\n",
    "        \n",
    "        #1st layer has two convolution functions (total = 2)\n",
    "        #input channels = 3\n",
    "        #output channels = 64\n",
    "        #no of layers = 2\n",
    "        self.conv1_1 = self.convlayers('conv1_1', 3, 64, self.img)\n",
    "        self.conv1_2 = self.convlayers('conv1_2', 64, 64, self.convl_1)  \n",
    "        #max pool layer\n",
    "        self.pool_1 = self.pooll(self.convl_2, 'pool_1')\n",
    "        \n",
    "        #2nd layer has two convolution functions (total = 4)\n",
    "        #input channels = 64\n",
    "        #output channels = 128\n",
    "        #no of layers = 2\n",
    "        self.conv2_1 = self.convlayers('conv2_1', 64, 128, self.pool_1)\n",
    "        self.conv2_2 = self.convlayers('conv2_2', 128, 128, self.conv2_1)\n",
    "        #max pool layer\n",
    "        self.pool_2 = self.pooll(self.conv2_2, 'pool_2')\n",
    "        \n",
    "        #3rd layer has three convolution functions (total = 7)\n",
    "        #input channel = 128\n",
    "        #output channels = 256\n",
    "        #no of layers = 3\n",
    "        self.conv3_1 = self.convlayers('conv3_1', 128, 256, self.pool_2)\n",
    "        self.conv3_2 = self.convlayers('conv3_2', 256, 256, self.conv3_1)\n",
    "        self.conv3_3 = self.convlayers('conv3_3', 256, 256, self.conv3_2)\n",
    "        #max pool layer\n",
    "        self.pool_3 = self.pool(self.conv3_3, 'pool_3')\n",
    "        \n",
    "        #4th layer has three convolution functions (total = 10)\n",
    "        #input channels = 256\n",
    "        #output channels = 512\n",
    "        #no of layers = 3\n",
    "        self.conv4_1 = self.convlayers('conv4_1', 256, 512, self.pool_3)\n",
    "        self.conv4_2 = self.convlayers('conv4_2', 512, 512, self.conv4_1)\n",
    "        self.conv4_3 = self.convlayers('conv4_3', 512, 512, self.conv4_2)\n",
    "        #max pool layer\n",
    "        self.pool_4 = self.pool(self.conv4_3, 'pool_4')\n",
    "        \n",
    "        #5th layer has three convolution functions (total = 13)\n",
    "        #input channels = 512\n",
    "        #output channels = 512\n",
    "        #no of layers = 3\n",
    "        self.conv5_1 = self.convlayers('conv5_1', 512, 512, self.pool_4)\n",
    "        self.conv5_2 = self.convlayers('conv5_2', 512, 512, self.conv5_1)\n",
    "        self.conv5_3 = self.convlayers('conv5_3', 512, 512, self.conv5_2)\n",
    "        #max pool layer\n",
    "        self.pool_5 = self.pool(self.conv5_3, 'pool_5')\n",
    "        \n",
    "        #flattening... please go through \"example for reshape\"\n",
    "        shape = tf.shape(self.pool_5)\n",
    "        self.pool_5_flat = tf.reshape(self.pool_5, [-1, 7*7*512])\n",
    "        \n",
    "        #6th layer has one computation (total = 14)\n",
    "        #fully connected layer 1 .. 4096\n",
    "        self.fc1 = self.fc_layers(self.pool_5_flat, shape[1]*shape[2]*shape[3], 4096, 'fc1')\n",
    "        #adding dropouts\n",
    "        #self.fc1d = tf.nn.dropout(fc1, keep_prob=0.5)\n",
    "        \n",
    "        #7th layer has one computation (total = 15)\n",
    "        #fully connected layer 2 .. 4096\n",
    "        self.fc2 = self.fc_layers(self.fc1, 4096, 4096, 'fc2')\n",
    "        #adding dropouts\n",
    "        #self.fc2d = tf.nn.dropout(fc2, keep_prob=0.5)\n",
    "        \n",
    "        #8th layer has one computation (total = 16)... hence VGG 16\n",
    "        #fully connected layer 3 .. 1000\n",
    "        fcw = tf.Variable(tf.truncated_normal([4096, 1000], mean = 0, stddev = 1.0, name='fc5_Weights'))\n",
    "        fcb = tf.Variable(tf.constant(1.0, shape=1000, name = 'fc5_bias'))\n",
    "            \n",
    "        self.fc3 = tf.nn.bias_add(tf.matmul(self.fc2, fcw), fcb)\n",
    "        \n",
    "        #self.prob = tf.nn.softmax(self.fc3, name = 'prob')\n",
    "        \n",
    "        print(\"build model finished\")\n",
    "        \n",
    "        #return self.fc3\n",
    "        #return self.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4, 3, 3, 2]), array([ 4, 18]), array([3, 3, 2]), 18]\n"
     ]
    }
   ],
   "source": [
    "# example for reshape\n",
    "import numpy as np\n",
    "x = tf.Variable(tf.truncated_normal(shape=[4,3,3,2], mean = 0, stddev=1.0))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "shape = tf.shape(x)\n",
    "y = tf.reshape(x, [-1,shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run([shape, tf.shape(y), shape[1:], shape[1]*shape[2]*shape[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(x):\n",
    "    x = tf.convert_to_tensor(x, tf.float32)\n",
    "    mean, variance = tf.nn.moments(x, axes=[0,1,2])\n",
    "    x_normalized = tf.nn.batch_norm_with_global_normalization(t=x, m = mean, v= variance, beta=None, \n",
    "                                                                gamma=None, variance_epsilon=1e-7, \n",
    "                                                                scale_after_normalization=None)\n",
    "    return x_normalized.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convlayers() missing 4 required positional arguments: 'curr_layer_str', 'input_ch', 'next_ch', and 'conv_ip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5a083e1e9ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mvgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-704f8e4b10bf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#predefining functions and variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: convlayers() missing 4 required positional arguments: 'curr_layer_str', 'input_ch', 'next_ch', and 'conv_ip'"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "vgg = VGG16(x)\n",
    "prob = vgg.fc3\n",
    "\n",
    "#we need to pass one hot encoded y for softmax_cross_entropy\n",
    "#when using sparse_softmax_cross_entropy, no need of one hot encoding of y\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prob, labels = y))\n",
    "train_operation = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prob, 1), y)\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "      \n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "import time\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  \n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  num_examples = len(x_train)\n",
    "  \n",
    "  print(\"Training....\\n\")\n",
    "  print(\"For Batch size...\", BATCH_SIZE)\n",
    "  \n",
    "  for i in range(EPOCHS):\n",
    "    start = time.process_time()\n",
    "    \n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "      end = offset + BATCH_SIZE\n",
    "\n",
    "      batch_x, batch_y = x_train[offset:end], y_train[offset:end]\n",
    "      sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "      \n",
    "    \n",
    "\n",
    "    validation_accuracy = evaluate(x_val, y_val)\n",
    "    training_accuracy = evaluate(x_train, y_train)\n",
    "    print(\"EPOCH {} ...\".format(i+1))\n",
    "    print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "    print(\"Training Accuracy = {:.3f}\".format(training_accuracy))\n",
    "    print(\"Time taken by Epoch: \",i ,time.process_time() - start)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
